{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table Of Contents\n",
    " 1. [Caricamento dei dati](#load)<br>\n",
    "     1.1 [Grafici di esempio](#esempi)\n",
    " 2. [Calcolo delle variabili di riassunto](#variabili)\n",
    " 3. [Analisi esplorativa con `PCA`, `ICA`, `t-SNE`](#esplorativa)\n",
    " 4. [Modello multinomiale](#multinomiale)\n",
    " 5. [Analisi discriminante](#lda-qda)\n",
    " 6. [Alberi di regressione](#tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funzioni base\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import seaborn as sns\n",
    "import tqdm\n",
    "\n",
    "# Font di LaTeX\n",
    "# from matplotlib import rc\n",
    "\n",
    "# Scikit-Learn\n",
    "from sklearn.model_selection import train_test_split, ParameterGrid\n",
    "from sklearn.decomposition import PCA, FastICA\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis, LinearDiscriminantAnalysis\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "import graphviz\n",
    "# Funzioni custom\n",
    "from funzioni import AbsMeanVarDeriv, Whiten,ScatterGroup, MatriceConfusione, indice_gini\n",
    "from funzioni import tasso_errata_classificazione, grafico_metrica_iperparametro, grafico_metrica_iperparametri\n",
    "from funzioni.grafici import grafico_importanza_variabili"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Caricamento dei dati <a id=load> </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_DATA = './PhonePi/data/'\n",
    "FIG_PATH = './figure/'\n",
    "DIR = [os.path.join(PATH_DATA, o) for o in os.listdir(PATH_DATA) \n",
    "                    if os.path.isdir(os.path.join(PATH_DATA,o))]\n",
    "tipo=[(dir.split(\"/\")[-1]).split(\".\")[0] for dir in DIR]\n",
    "tipo=[dir.split(\"-\")[0] for dir in tipo]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 150 # numero osservazioni per intervallo\n",
    "nomi_colonna=[\"user\",\"azione\"]\n",
    "nomi_colonna.extend([\"a\"+str(i) for i in range(p)])\n",
    "nomi_colonna\n",
    "X=pd.DataFrame(columns=nomi_colonna)\n",
    "\n",
    "for i in tqdm.tqdm(range(len(DIR))):\n",
    "    data = pd.read_csv(DIR[i] + \"/accelerometer.txt\", names = [\"user\", \"type\", \"t\", \"ax\", \"ay\", \"az\"]) # lettura dati\n",
    "    data[\"t\"] = data[\"t\"] - data[\"t\"].iloc[0] # t0 = 0\n",
    "    data = data[(data[\"t\"] > 7000) & (data[\"t\"] < (data[\"t\"].max()-7000))] # tolti i primi e ultimi 7 secondi\n",
    "    data.reset_index(drop=True, inplace=True) # ripristinati gli indici da 0 in avanti\n",
    "    data[\"a\"] = (pd.to_numeric(data[\"ax\"])**2 + pd.to_numeric(data[\"ay\"])**2 + pd.to_numeric(data[\"az\"])**2)**0.5 # accelerazione in modulo\n",
    "    nome = [data.user[j] for j in range(0,len(data)-p, p)] # intervalli di dt*100ms\n",
    "    tipologia=[tipo[i]]*len(nome)\n",
    "    righe=[[nome[j],tipologia[j]] for j in range(len(nome))]\n",
    "    [righe[j].extend(list(data.a[j*p:(j+1)*p])) for j in range(len(nome))]\n",
    "    X=pd.concat([X,pd.DataFrame(righe,columns=nomi_colonna)],ignore_index=True) # ignore_index=T per avere indici consecutivi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Grafici di esempio <a id=esempi> </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIRM = ['./PhonePi/data/scale-martina',\n",
    "        './PhonePi/data/salti-daniele',\n",
    "        './PhonePi/data/shake-anna']\n",
    "\n",
    "plt.figure(figsize=(13,5.5*len(DIRM)))\n",
    "nrow = len(DIRM)\n",
    "for i in tqdm.tqdm(range(len(DIRM))):\n",
    "    data = pd.read_csv(DIRM[i] + \"/accelerometer.txt\", names = [\"user\", \"type\", \"t\", \"ax\", \"ay\", \"az\"])\n",
    "    data[\"t\"] = data[\"t\"] - data[\"t\"].iloc[0]\n",
    "    data = data[(data[\"t\"] > 7000) & (data[\"t\"] < (data[\"t\"].max()-7000))]\n",
    "    data[\"a\"] = (pd.to_numeric(data[\"ax\"])**2 + pd.to_numeric(data[\"ay\"])**2 + pd.to_numeric(data[\"az\"])**2)**0.5 # accelerazione in modulo\n",
    "    ax = plt.subplot(nrow, 1, i+1, ylim=(0,120), xlim = (10000,30000))\n",
    "    ax.set_ylabel(r\"$\\|a\\|\\;(\\mathrm{ m/s}^2)$\", rotation=0)\n",
    "    ax.yaxis.set_label_coords(-0.1,0.7)\n",
    "    ax.set_xlabel(r\"$t \\;(\\mathrm{ ms})$\")\n",
    "    ax.set_title((DIRM[i].split(\"/\")[-1]).split(\"-\")[0])\n",
    "    plt.plot(data[\"t\"],data[\"a\"])\n",
    "    plt.savefig(FIG_PATH+\"espl.png\", dpi=150)    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Calcolo delle variabili di riassunto <a id=variabili> </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = X.azione\n",
    "X.drop(\"azione\", axis=1, inplace=True)\n",
    "Xnum = X.drop(\"user\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxA = Xnum.max(1) # massimo accelerazione\n",
    "MVDeriv = AbsMeanVarDeriv(Xnum, 10) # variazione media della derivata\n",
    "Mean = Xnum.mean(axis=1)\n",
    "Var = Xnum.var(axis=1)\n",
    "Med = Xnum.median(axis=1)\n",
    "Min = Xnum.min(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "espl = pd.concat([maxA, MVDeriv, Mean, Var, Med, Min], axis=1)\n",
    "espl.columns=[\"maxA\", \"MVDeriv\", \"meanA\", \"Var\", \"Med\", \"Min\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.to_pickle(\"X-2s.pkl\")\n",
    "y.to_pickle(\"y-2s.pkl\")\n",
    "espl.to_pickle(\"espl.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(espl, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Analisi esplorativa con `PCA`, `ICA`, `t-SNE` <a id=esplorativa> </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sbiancamento dei dati\n",
    "esplWh = Whiten().fit_transform(espl)\n",
    "\n",
    "pca = PCA(n_components=2, random_state=42)\n",
    "esplPCA = pca.fit_transform(esplWh)\n",
    "\n",
    "ica = FastICA(n_components=2, random_state=42)\n",
    "esplICA = ica.fit_transform(esplWh)\n",
    "\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "esplTSNE = tsne.fit_transform(esplWh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for title,dat in zip([\"PCA\",\"ICA\",\"t-SNE\"], [esplPCA, esplICA, esplTSNE]):\n",
    "    fig, ax = ScatterGroup(pd.DataFrame(dat, columns=[\"Prima componente\", \"Seconda componente\"]),\n",
    "                       grp=y, palette=\"colorblind\")\n",
    "    fig.set_figwidth(11)\n",
    "    fig.set_figheight(6)\n",
    "    ax.set_title(title)\n",
    "    plt.legend(bbox_to_anchor=(1,0.7))\n",
    "    plt.savefig(FIG_PATH+title+\".png\", bbox_inches=\"tight\", dpi=180)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Modello multinomiale <a id=multinomiale> </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glmMult = LogisticRegression(penalty=\"l2\", C=float(\"inf\"), random_state=42, multi_class=\"multinomial\",\n",
    "                             solver=\"newton-cg\", max_iter=1000)\n",
    "fit = glmMult.fit(X_train, y_train)\n",
    "y_pred = fit.predict(X_val)\n",
    "\n",
    "acc_mn = 100*accuracy_score(y_val, y_pred)\n",
    "print(\"LogisticRegression(multi_class=\\\"multinomial\\\"): {:.1f}% di accuratezza\".format(acc_mn))\n",
    "MatriceConfusione(y_val, y_pred)\n",
    "plt.savefig(FIG_PATH+\"confusionMatrix-Mn.png\", dpi=300, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Analisi discriminante lineare e quadratica <a id=lda-qda> </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LinearDiscriminantAnalysis()\n",
    "X_lda=lda.fit(X_train, y_train)\n",
    "y_pred_lda = lda.predict(X_val)\n",
    "acc_lda = 100*accuracy_score(y_val, y_pred_lda)\n",
    "print(\"Accuratezza LDA: {:.1f}%\".format(acc_lda))\n",
    "MatriceConfusione(y_val, y_pred_lda,nome_immagine=FIG_PATH+\"confusionMatrix-LDA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qda = QuadraticDiscriminantAnalysis()\n",
    "qda.fit(X_train, y_train)\n",
    "y_pred_qda = qda.predict(X_val)\n",
    "acc_qda = 100*accuracy_score(y_val, y_pred_qda)\n",
    "print(\"Accuratezza QDA: {:.1f}%\".format(acc_qda))\n",
    "MatriceConfusione(y_val, y_pred_qda,nome_immagine=FIG_PATH+\"confusionMatrix-QDA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.bincount((y_pred_qda == \"shake\"))\n",
    "sum(y_pred_qda == \"shake\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Da sviluppare, LDA e QDA con penalizzazione per gli shake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = np.array(y_train.value_counts()/y_train.value_counts().sum())\n",
    "lda = LinearDiscriminantAnalysis(priors=weights)\n",
    "X_lda=lda.fit(X_train, y_train)\n",
    "y_pred_lda = lda.predict(X_val)\n",
    "lista_acc_lda = [100*accuracy_score(y_val, y_pred_lda),]\n",
    "lista_veri_positivi_lda= [100*(confusion_matrix(y_val, y_pred_lda)[-1,-1]/confusion_matrix(y_val, y_pred_lda)[:,-1].sum()),]\n",
    "lista_numero_sbagliati_lda= [confusion_matrix(y_val, y_pred_lda)[:-1,-1].sum(),]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = y_train.value_counts()/y_train.value_counts().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_acc_lda = []\n",
    "lista_veri_positivi_lda = []\n",
    "lista_numero_sbagliati_lda = []\n",
    "for i in np.arange(1,10,0.5):\n",
    "    weights = np.array(y_train.value_counts()/y_train.value_counts().sum())\n",
    "    weights[1] /= i\n",
    "    weights = weights/weights.sum()\n",
    "    lda = LinearDiscriminantAnalysis(priors=weights)\n",
    "    X_lda=lda.fit(X_train, y_train)\n",
    "    y_pred_lda = lda.predict(X_val)\n",
    "    lista_acc_lda.append(100*accuracy_score(y_val, y_pred_lda))\n",
    "    confMatrix = confusion_matrix(y_val, y_pred_lda, labels=lab)\n",
    "    lista_veri_positivi_lda.append(100*(confMatrix[-1,-1]/confMatrix[:,-1].sum()))\n",
    "    lista_numero_sbagliati_lda.append(confMatrix[:-1,-1].sum())\n",
    "    #print(i)\n",
    "    #print(\"Accuratezza LDA: {:.2f}%\".format(acc_lda))\n",
    "    #print(\"Tasso veri positivi LDA: {:.2f}%\".format(veri_positivi))\n",
    "    #print(\"Numero shake sbagliati LDA: {:.2f}\".format(numero_sbagliati))\n",
    "    #print(\"_______________\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab = y.unique()\n",
    "lab.sort()\n",
    "confusion_matrix(y_val, y_pred_lda, labels=lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_veri_positivi_lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab = y.unique()\n",
    "lab.sort()\n",
    "sns.heatmap(confusion_matrix(y_val, y_pred_lda), yticklabels=y.unique(), xticklabels=y.unique())\n",
    "sns.heatmap(confusion_matrix(y_val, y_pred_lda), yticklabels=lab, xticklabels=lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = np.array(y_train.value_counts()/y_train.value_counts().sum())\n",
    "qda = QuadraticDiscriminantAnalysis(priors=weights)\n",
    "qda.fit(X_train, y_train)\n",
    "y_pred_qda = qda.predict(X_val)\n",
    "lista_acc_qda = [100*accuracy_score(y_val, y_pred_qda),]\n",
    "lista_veri_positivi_qda= [100*(confusion_matrix(y_val, y_pred_qda)[-1,-1]/confusion_matrix(y_val, y_pred_qda)[:,-1].sum()),]\n",
    "lista_numero_sbagliati_qda= [confusion_matrix(y_val, y_pred_qda)[:-1,-1].sum(),]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_acc_qda = []\n",
    "lista_veri_positivi_qda = []\n",
    "lista_numero_sbagliati_qda = []\n",
    "for i in np.arange(1,10,0.5):\n",
    "    weights = np.array(y_train.value_counts()/y_train.value_counts().sum())\n",
    "    weights[1] /= i\n",
    "    weights = weights/weights.sum()\n",
    "    qda = QuadraticDiscriminantAnalysis(priors=weights)\n",
    "    X_qda=qda.fit(X_train, y_train)\n",
    "    y_pred_qda = qda.predict(X_val)\n",
    "    lista_acc_qda.append(100*accuracy_score(y_val, y_pred_qda))\n",
    "    confMatrix = confusion_matrix(y_val, y_pred_qda, labels=lab)\n",
    "    lista_veri_positivi_qda.append(100*(confMatrix[-1,-1]/confMatrix[:,-1].sum()))\n",
    "    lista_numero_sbagliati_qda.append(confMatrix[:-1,-1].sum())\n",
    "    #print(i)\n",
    "    #print(\"Accuratezza LDA: {:.2f}%\".format(acc_lda))\n",
    "    #print(\"Tasso veri positivi LDA: {:.2f}%\".format(veri_positivi))\n",
    "    #print(\"Numero shake sbagliati LDA: {:.2f}\".format(numero_sbagliati))\n",
    "    #print(\"_______________\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_veri_positivi_qda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in pratica per pesi crescenti assegnati alla classe dello shake si nota che la percentuale di veri positivi aumenta\n",
    "# e l'accuratezza ovviamente diminuisce. Se vogliamo che l'errore di classificare shake qualcosa che non è shake sia nullo\n",
    "# (o <0.01) scegliamo il primo peso che mi porta ad avere veri_positivi uguale a 100 (o 99) in modo da scegliere \n",
    "# il modello con l'accuratezza migliore fra quelli che non sbagliano lo shake\n",
    "\n",
    "plt.plot(lista_acc_lda, label=\"accuracy\")\n",
    "plt.plot(lista_veri_positivi_lda, label=\"veri positivi\")\n",
    "plt.legend()\n",
    "#plt.plot(lista_numero_sbagliati_lda)\n",
    "plt.title(\"LDA\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(lista_acc_qda, label=\"accuracy\")\n",
    "plt.plot(lista_veri_positivi_qda, label=\"veri positivi\")\n",
    "plt.legend()\n",
    "#plt.plot(lista_numero_sbagliati_qda)\n",
    "plt.title(\"QDA\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seleziono il peso da assegnare alla classe shake per avere un tasso di veri positivi del 99%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_veri_positivi_lda=np.array(lista_veri_positivi_lda)\n",
    "num_iterazione_lda=np.min(np.where(lista_veri_positivi_lda>99))\n",
    "peso_shake_lda=np.arange(1.1,8,0.1)[num_iterazione_lda]\n",
    "peso_shake_lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_veri_positivi_qda=np.array(lista_veri_positivi_qda)\n",
    "num_iterazione_qda=np.min(np.where(lista_veri_positivi_qda>99))\n",
    "peso_shake_qda=np.arange(1.1,8,0.1)[num_iterazione_qda]\n",
    "peso_shake_qda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = np.array(y_train.value_counts()/y_train.value_counts().sum())\n",
    "weights[-1] /= peso_shake_lda\n",
    "weights = weights/weights.sum()\n",
    "lda = LinearDiscriminantAnalysis(priors=weights)\n",
    "X_lda=lda.fit(X_train, y_train)\n",
    "y_pred_lda = lda.predict(X_val)\n",
    "acc_lda = 100*accuracy_score(y_val, y_pred_lda)\n",
    "print(\"Accuratezza QDA: {:.1f}%\".format(acc_lda))\n",
    "MatriceConfusione(y_val, y_pred_lda,nome_immagine=FIG_PATH+\"confusionMatrix-LDA-penalizzata\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = np.array(y_train.value_counts()/y_train.value_counts().sum())\n",
    "weights[-1] /= peso_shake_qda\n",
    "weights = weights/weights.sum()\n",
    "qda = QuadraticDiscriminantAnalysis(priors=weights)\n",
    "qda.fit(X_train, y_train)\n",
    "y_pred_qda = qda.predict(X_val)\n",
    "acc_qda = 100*accuracy_score(y_val, y_pred_qda)\n",
    "print(\"Accuratezza QDA: {:.1f}%\".format(acc_qda))\n",
    "MatriceConfusione(y_val, y_pred_qda,nome_immagine=FIG_PATH+\"confusionMatrix-QDA-penalizzata\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Alberi di regressione <a id=tree> </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Albero stimato sul training, senza vincoli (albero completo)\n",
    "dtc = DecisionTreeClassifier(random_state=42)\n",
    "dtc.fit(X_train, y_train)\n",
    "y_pred = dtc.predict(X_val)\n",
    "acc_dtcFull = 100*accuracy_score(y_val, y_pred)\n",
    "\n",
    "print(\"Accuratezza DecisionTreeClassifier(): {:.2f}%\".format(acc_dtcFull))\n",
    "MatriceConfusione(y_val, y_pred)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxDepth = dtc.tree_.max_depth\n",
    "minObs = len(X_train) // 2\n",
    "print(\"Profondità dell'albero allenato senza restrizioni: {}\".format(maxDepth))\n",
    "print(\"Massimo numero minimo di osservazioni in una foglia: {}\".format(minObs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = ParameterGrid({\n",
    "    'max_depth': np.arange(1, dtc.tree_.max_depth),\n",
    "    'min_samples_leaf': 2 ** np.arange(int(np.log2(minObs) + 1)),\n",
    "})\n",
    "print(param_grid.param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "risultati = []\n",
    "\n",
    "for params in tqdm.tqdm(param_grid):\n",
    "    dtc = DecisionTreeClassifier(random_state=42, **params)\n",
    "    dtc.fit(X_train, y_train)\n",
    "    y_pred = dtc.predict(X_val)\n",
    "    params[\"accuracy_score\"] = accuracy_score(y_val, y_pred)\n",
    "    risultati.append(params)\n",
    "\n",
    "risultati = pd.DataFrame(risultati).sort_values([\"accuracy_score\", \"max_depth\"], ascending=[False, True])\n",
    "risultati.reset_index(drop=True, inplace=True)\n",
    "print(\"Primi 5:\")\n",
    "display(risultati.head())\n",
    "\n",
    "print(\"Ultimi 5:\")\n",
    "risultati.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(121)\n",
    "grafico_metrica_iperparametro(risultati, \"max_depth\", \"accuracy_score\", alpha=0.5)\n",
    "\n",
    "plt.subplot(122)\n",
    "grafico_metrica_iperparametro(risultati, \"min_samples_leaf\", \"accuracy_score\", alpha=0.5)\n",
    "plt.xscale(\"log\", basex=2)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "grafico_metrica_iperparametri(risultati, \"max_depth\", \"min_samples_leaf\", \"accuracy_score\")\n",
    "plt.yscale(\"log\", basey=2)\n",
    "plt.savefig(FIG_PATH + \"iperparametri-Tree.png\", dpi=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth = risultati.loc[0, \"max_depth\"]\n",
    "min_samples_leaf = risultati.loc[0, \"min_samples_leaf\"]\n",
    "\n",
    "dtcTun = DecisionTreeClassifier(max_depth=max_depth, min_samples_leaf=min_samples_leaf, random_state=42)\n",
    "dtcTun.fit(X_train, y_train)\n",
    "\n",
    "y_pred = dtcTun.predict(X_val)\n",
    "acc_dtcTun = 100*accuracy_score(y_val, y_pred)\n",
    "print(\"profondità ottimale:\",max_depth)\n",
    "print(\"numero ottimale minimo di unità per foglia:\",min_samples_leaf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuratezza DecisionTreeClassifier(): {:.1f}%\".format(acc_dtcFull))\n",
    "print(\"Accuratezza DecisionTreeClassifier(max_depth={}, min_samples_leaf={}): {:.1f}%\".format(\n",
    "    max_depth, min_samples_leaf, acc_dtcTun))\n",
    "print(confusion_matrix(y_val, y_pred))\n",
    "\n",
    "MatriceConfusione(y_val, y_pred)\n",
    "plt.savefig(FIG_PATH + \"confusionMatrix-Tree.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importanze = dtcTun.feature_importances_\n",
    "variabili = espl.columns\n",
    "\n",
    "grafico_importanza_variabili(importanze, variabili)\n",
    "plt.savefig(FIG_PATH + \"importance-Tree.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Salvataggio dei risultati"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tabella accuracy in file LaTeX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tableEnvBegin = \"\\\\begin{table}[H]\\n\\\\centering\"\n",
    "tableEnvEnd = \"\\end{table}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = pd.DataFrame([[\"Multinomiale\", acc_mn],\n",
    "             [\"LDA\", acc_lda],\n",
    "             [\"QDA\", acc_qda],\n",
    "             [\"Decision Tree\", acc_dtcFull],\n",
    "             [\"Pruned Decision Tree\", acc_dtcTun]], columns=[\"Modello\", \"Accuracy %\"])\n",
    "\n",
    "accuracy.sort_values(\"Accuracy %\", inplace=True)\n",
    "caption='\\\\caption{Accuratezza per i modelli adattati.}\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./relazione/tex/accuracy-table.tex\", mode=\"w\") as file:\n",
    "    file.write(tableEnvBegin + caption + accuracy.to_latex(index=False, float_format=\"%.2f\", column_format=\"cc\") + tableEnvEnd)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
