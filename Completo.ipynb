{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table Of Contents\n",
    " 1. [Analisi esplorativa con `PCA`, `ICA`, `t-SNE`](#esplorativa)\n",
    " 2. [Modello multinomiale](#multinomiale)<br>\n",
    "     2.1 [Modello multinomiale penalizzato](#multinomiale-pen)\n",
    " 3. [Analisi discriminante](#lda-qda)<br>\n",
    "     3.1 [Analisi discriminante penalizzata](#da-pen)\n",
    " 4. [Alberi di regressione](#tree)<br>\n",
    "     4.1 [Alberi di regressione penalizzati](#tree-penalized)<br>\n",
    "\n",
    "END. [Salvataggio dei dati](#save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funzioni base:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import seaborn as sns\n",
    "import tqdm\n",
    "\n",
    "# Font di LaTeX\n",
    "# from matplotlib import rc\n",
    "\n",
    "# Scikit-Learn\n",
    "from sklearn.model_selection import train_test_split, ParameterGrid\n",
    "from sklearn.decomposition import PCA, FastICA\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis, LinearDiscriminantAnalysis\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "import graphviz\n",
    "# Funzioni custom\n",
    "from funzioni import AbsMeanVarDeriv, Whiten,ScatterGroup, MatriceConfusione, indice_gini, DistGroup\n",
    "from funzioni import tasso_errata_classificazione, grafico_metrica_iperparametro, grafico_metrica_iperparametri\n",
    "from funzioni.grafici import grafico_importanza_variabili"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Analisi esplorativa con `PCA`, `ICA`, `t-SNE` <a id=esplorativa> </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_DATA = './PhonePi/data/'\n",
    "FIG_PATH = './figure/'\n",
    "DIR = [os.path.join(PATH_DATA, o) for o in os.listdir(PATH_DATA) \n",
    "                    if os.path.isdir(os.path.join(PATH_DATA,o))]\n",
    "tipo=[(dir.split(\"/\")[-1]).split(\".\")[0] for dir in DIR]\n",
    "tipo=[dir.split(\"-\")[0] for dir in tipo]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.read_pickle(\"y-2s.pkl\")\n",
    "X_train = pd.read_pickle(\"X_train.pkl\")\n",
    "y_train = pd.read_pickle(\"y_train.pkl\")\n",
    "X_val = pd.read_pickle(\"X_val.pkl\")\n",
    "y_val = pd.read_pickle(\"y_val.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in X_train.columns:\n",
    "    DistGroup(X_train[col], grp=y, leg_loc = (1.4, 0.8),\n",
    "              palette=\"colorblind\", file = FIG_PATH + col + \".png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sbiancamento dei dati\n",
    "XWh = Whiten().fit_transform(X_train)\n",
    "\n",
    "pca = PCA(n_components=2, random_state=42)\n",
    "XPCA = pca.fit_transform(XWh)\n",
    "\n",
    "ica = FastICA(n_components=2, random_state=42)\n",
    "XICA = ica.fit_transform(XWh)\n",
    "\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "XTSNE = tsne.fit_transform(XWh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for title,dat in zip([\"PCA\",\"ICA\",\"t-SNE\"], [XPCA, XICA, XTSNE]):\n",
    "    fig, ax = ScatterGroup(pd.DataFrame(dat, columns=[\"Prima componente\", \"Seconda componente\"]),\n",
    "                       grp=y, palette=\"colorblind\")\n",
    "    fig.set_figwidth(11)\n",
    "    fig.set_figheight(6)\n",
    "    ax.set_title(title)\n",
    "    plt.legend(bbox_to_anchor=(1,0.7))\n",
    "    plt.savefig(FIG_PATH+title+\".png\", bbox_inches=\"tight\", dpi=180)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Modello multinomiale <a id=multinomiale> </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glmMult = LogisticRegression(penalty=\"l2\", C=float(\"inf\"), random_state=42, multi_class=\"multinomial\",\n",
    "                             solver=\"newton-cg\", max_iter=300)\n",
    "fit = glmMult.fit(X_train, y_train)\n",
    "y_pred = fit.predict(X_val)\n",
    "\n",
    "acc_mn = 100*accuracy_score(y_val, y_pred)\n",
    "print(\"Regressione multinomiale: {:.1f}% di accuratezza\".format(acc_mn))\n",
    "MatriceConfusione(y_val, y_pred, nome_immagine=FIG_PATH+\"confusionMatrix-Mn.png\", title=\"Multinomiale\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Modello multinomiale penalizzato <a id=multinomiale-pen></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab = y.unique()\n",
    "lab.sort()\n",
    "print(lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PesiShakeMn(val):\n",
    "    '''\n",
    "    Funzione per modificare i pesi nel modello multinomiale\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    Modello : Funzione di classificazione (LDA o QDA)\n",
    "    \n",
    "    val : array di valori per cui dividere il peso base della classe shake\n",
    "    '''\n",
    "    iteraz = []\n",
    "    lista_acc=[]\n",
    "    lista_veri_positivi=[]\n",
    "    peso_shake=[]\n",
    "    for i in tqdm.tqdm(val):\n",
    "        iteraz.append(i)\n",
    "        weights = y_train.value_counts()/y_train.value_counts().sum()\n",
    "        weights[\"shake\"]/=i\n",
    "        weights/=weights.sum()\n",
    "        w = {ind:weights[ind] for ind in weights.index}\n",
    "        peso_shake.append(weights[\"shake\"])\n",
    "        model = LogisticRegression(penalty=\"l2\", C=float(\"inf\"), random_state=42, \n",
    "                               multi_class=\"multinomial\",solver=\"newton-cg\", max_iter=100, class_weight=w)\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_val)\n",
    "        lista_acc.append(100*accuracy_score(y_val, y_pred))\n",
    "        lista_veri_positivi.append(100*(confusion_matrix(y_val, y_pred, labels=lab)[-1,-1]/confusion_matrix(y_val, y_pred,labels=lab)[:,-1].sum()))\n",
    "        \n",
    "    return peso_shake, lista_acc, lista_veri_positivi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pesi = np.arange(1, 13, 0.5)\n",
    "peso_mn, lista_acc_mn, lista_veri_positivi_mn = PesiShakeMn(val=pesi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_acc_mn[-9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(lista_acc_mn, label = \"accuratezza\")\n",
    "plt.plot(lista_veri_positivi_mn, label = \"shake corretti\")\n",
    "plt.title(\"Multinomiale\")\n",
    "plt.xlabel(\"iterazione\")\n",
    "plt.ylabel(\"%\")\n",
    "plt.legend(bbox_to_anchor=(1.31,0.7))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = pesi[lista_veri_positivi_mn.index(100)]\n",
    "weights = y_train.value_counts()/y_train.value_counts().sum()\n",
    "weights[\"shake\"]/=i\n",
    "weights/=weights.sum()\n",
    "w = {ind:weights[ind] for ind in weights.index}\n",
    "model = LogisticRegression(penalty=\"l2\", C=float(\"inf\"), random_state=42, \n",
    "                               multi_class=\"multinomial\",solver=\"newton-cg\", max_iter=100, class_weight=w)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_val)\n",
    "acc_mn_pen = 100*accuracy_score(y_val, y_pred)\n",
    "print(\"Accuratezza Multinomiale penalizzata: {:.1f}%\".format(acc_mn_pen))\n",
    "MatriceConfusione(y_val, y_pred,nome_immagine=FIG_PATH+\"confusionMatrix-Mn-penalizzata\", title=\"Multinomiale pesata\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------- TODO ---------------------#\n",
    "# Prendere il peso migliore per la multinomiale #\n",
    "#-----------------------------------------------#\n",
    "#w = ...\n",
    "\n",
    "\n",
    "#glmMult = LogisticRegression(penalty=\"l2\", C=float(\"inf\"), random_state=42, multi_class=\"multinomial\",\n",
    "#                              solver=\"newton-cg\", max_iter=300, class_weight=w)\n",
    "#fit = glmMult.fit(X_train, y_train)\n",
    "# y_pred = fit.predict(X_val)\n",
    "\n",
    "# acc_mn_pen = 100*accuracy_score(y_val, y_pred)\n",
    "# print(\"Regressione multinomiale penalizzata: {:.1f}% di accuratezza\".format(acc_mn_pen))\n",
    "# MatriceConfusione(y_val, y_pred)\n",
    "# plt.savefig(FIG_PATH+\"confusionMatrix-Mn-penalizzata.png\", dpi=300, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Analisi discriminante lineare e quadratica <a id=lda-qda> </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LinearDiscriminantAnalysis()\n",
    "X_lda=lda.fit(X_train, y_train)\n",
    "y_pred_lda = lda.predict(X_val)\n",
    "acc_lda = 100*accuracy_score(y_val, y_pred_lda)\n",
    "print(\"Accuratezza LDA: {:.1f}%\".format(acc_lda))\n",
    "MatriceConfusione(y_val, y_pred_lda,nome_immagine=FIG_PATH+\"confusionMatrix-LDA\", title=\"LDA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qda = QuadraticDiscriminantAnalysis()\n",
    "qda.fit(X_train, y_train)\n",
    "y_pred_qda = qda.predict(X_val)\n",
    "acc_qda = 100*accuracy_score(y_val, y_pred_qda)\n",
    "print(\"Accuratezza QDA: {:.1f}%\".format(acc_qda))\n",
    "MatriceConfusione(y_val, y_pred_qda,nome_immagine=FIG_PATH+\"confusionMatrix-QDA\", title=\"QDA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Analisi discriminante penalizzata <a id=da-pen> </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lda.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PesiShakeDA(Modello, val):\n",
    "    '''\n",
    "    Funzione per modificare i pesi delle analisi discriminanti lineare e quadratica.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    Modello : Funzione di classificazione (LDA o QDA)\n",
    "    \n",
    "    val : array di valori per cui dividere il peso base della classe shake\n",
    "    '''\n",
    "\n",
    "    lista_acc=[]\n",
    "    lista_veri_positivi=[]\n",
    "    w=[]\n",
    "    for i in val:\n",
    "        weights = np.array(y_train.value_counts()/y_train.value_counts().sum())\n",
    "        weights[-1] /= i\n",
    "        weights = weights/weights.sum()\n",
    "        w.append(weights[-1])\n",
    "        model = Modello(priors=weights)\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_val)\n",
    "        lista_acc.append(100*accuracy_score(y_val, y_pred))\n",
    "        lista_veri_positivi.append(100*(confusion_matrix(y_val, y_pred, labels=lab)[-1,-1]/confusion_matrix(y_val, y_pred,labels=lab)[:,-1].sum()))\n",
    "        \n",
    "    return w, lista_acc, lista_veri_positivi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA e QDA penalizzate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in pratica per pesi crescenti assegnati alla classe dello shake si nota che la percentuale di veri positivi aumenta\n",
    "# e l'accuratezza ovviamente diminuisce. Se vogliamo che l'errore di classificare shake qualcosa che non è shake sia nullo\n",
    "# (o <0.01) scegliamo il primo peso che mi porta ad avere veri_positivi uguale a 100 (o 99) in modo da scegliere \n",
    "# il modello con l'accuratezza migliore fra quelli che non sbagliano lo shake\n",
    "\n",
    "val = np.arange(1.1, 12, 0.1) # lista di divisori del peso per la classe\n",
    "\n",
    "pesi_lda, lista_acc_lda, lista_veri_positivi_lda = PesiShakeDA(LinearDiscriminantAnalysis, val)\n",
    "plt.plot(pesi_lda, lista_acc_lda, label = \"accuratezza\")\n",
    "plt.plot(pesi_lda, lista_veri_positivi_lda, label = \"shake corretti\")\n",
    "plt.title(\"LDA\")\n",
    "plt.xlabel(\"iterazione\")\n",
    "plt.ylabel(\"%\")\n",
    "plt.legend(bbox_to_anchor=(1.34,0.7))\n",
    "plt.show()\n",
    "\n",
    "pesi_qda, lista_acc_qda, lista_veri_positivi_qda = PesiShakeDA(QuadraticDiscriminantAnalysis, val)\n",
    "plt.plot(pesi_qda, lista_acc_qda, label = \"accuratezza\")\n",
    "plt.plot(pesi_qda, lista_veri_positivi_qda, label = \"shake corretti\")\n",
    "plt.title(\"QDA\")\n",
    "plt.xlabel(\"peso shake\")\n",
    "plt.ylabel(\"%\")\n",
    "plt.legend(bbox_to_anchor=(1.34,0.7))\n",
    "plt.savefig(FIG_PATH + \"acc-vs-veripos-qda\", bbox_inches=\"tight\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(pesi_qda)\n",
    "plt.xlabel(\"iterazione\")\n",
    "plt.ylabel(\"peso\")\n",
    "plt.savefig(FIG_PATH + \"andamento-pesi.png\", bbox_inches=\"tight\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_veri_positivi_qda[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_veri_positivi_lda=np.array(lista_veri_positivi_lda)\n",
    "num_iterazione_lda=np.min(np.where(lista_veri_positivi_lda>99))\n",
    "peso_shake_lda=np.arange(1.1,12,0.1)[num_iterazione_lda]\n",
    "peso_shake_lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_veri_positivi_qda=np.array(lista_veri_positivi_qda)\n",
    "num_iterazione_qda=np.min(np.where(lista_veri_positivi_qda>97))\n",
    "peso_shake_qda=np.arange(1.1,12,0.1)[num_iterazione_qda]\n",
    "peso_shake_qda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = np.array(y_train.value_counts()/y_train.value_counts().sum())\n",
    "weights[-1] /= peso_shake_lda\n",
    "weights = weights/weights.sum()\n",
    "lda = LinearDiscriminantAnalysis(priors=weights)\n",
    "X_lda=lda.fit(X_train, y_train)\n",
    "y_pred_lda = lda.predict(X_val)\n",
    "acc_lda_pen = 100*accuracy_score(y_val, y_pred_lda)\n",
    "print(\"Accuratezza LDA penalizzata: {:.1f}%\".format(acc_lda_pen))\n",
    "MatriceConfusione(y_val, y_pred_lda, nome_immagine=FIG_PATH+\"confusionMatrix-LDA-penalizzata\", title=\"LDA pesata\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = np.array(y_train.value_counts()/y_train.value_counts().sum())\n",
    "weights[-1] /= peso_shake_qda\n",
    "weights = weights/weights.sum()\n",
    "qda = QuadraticDiscriminantAnalysis(priors=weights)\n",
    "qda.fit(X_train, y_train)\n",
    "y_pred_qda = qda.predict(X_val)\n",
    "acc_qda_pen = 100*accuracy_score(y_val, y_pred_qda)\n",
    "print(\"Accuratezza QDA penalizzata: {:.1f}%\".format(acc_qda_pen))\n",
    "MatriceConfusione(y_val, y_pred_qda,nome_immagine=FIG_PATH+\"confusionMatrix-QDA-penalizzata\", title=\"QDA pesata\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Alberi di regressione <a id=tree> </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Albero stimato sul training, senza vincoli (albero completo)\n",
    "dtc = DecisionTreeClassifier(random_state=42)\n",
    "dtc.fit(X_train, y_train)\n",
    "y_pred = dtc.predict(X_val)\n",
    "acc_dtcFull = 100*accuracy_score(y_val, y_pred)\n",
    "\n",
    "print(\"Accuratezza DecisionTreeClassifier(): {:.2f}%\".format(acc_dtcFull))\n",
    "MatriceConfusione(y_val, y_pred, FIG_PATH+\"confusionMatrix-Tree\", title=\"Albero di regressione completo\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxDepth = dtc.tree_.max_depth\n",
    "minObs = len(X_train) // 2\n",
    "print(\"Profondità dell'albero allenato senza restrizioni: {}\".format(maxDepth))\n",
    "print(\"Massimo numero minimo di osservazioni in una foglia: {}\".format(minObs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = ParameterGrid({\n",
    "    'max_depth': np.arange(1, dtc.tree_.max_depth+1),\n",
    "    'min_samples_leaf': 2 ** np.arange(int(np.log2(minObs) + 1)),\n",
    "})\n",
    "print(param_grid.param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "risultati = []\n",
    "\n",
    "for params in tqdm.tqdm(param_grid):\n",
    "    dtc = DecisionTreeClassifier(random_state=42, **params)\n",
    "    dtc.fit(X_train, y_train)\n",
    "    y_pred = dtc.predict(X_val)\n",
    "    params[\"accuracy_score\"] = accuracy_score(y_val, y_pred)\n",
    "    risultati.append(params)\n",
    "\n",
    "risultati = pd.DataFrame(risultati).sort_values([\"accuracy_score\", \"max_depth\"], ascending=[False, True])\n",
    "risultati.reset_index(drop=True, inplace=True)\n",
    "print(\"Primi 5:\")\n",
    "display(risultati.head())\n",
    "\n",
    "print(\"Ultimi 5:\")\n",
    "risultati.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(121)\n",
    "grafico_metrica_iperparametro(risultati, \"max_depth\", \"accuracy_score\", alpha=0.5)\n",
    "\n",
    "plt.subplot(122)\n",
    "grafico_metrica_iperparametro(risultati, \"min_samples_leaf\", \"accuracy_score\", alpha=0.5)\n",
    "plt.xscale(\"log\", basex=2)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "grafico_metrica_iperparametri(risultati, \"max_depth\", \"min_samples_leaf\", \"accuracy_score\")\n",
    "plt.yscale(\"log\", basey=2)\n",
    "plt.savefig(FIG_PATH + \"iperparametri-Tree.png\", dpi=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth = risultati.loc[0, \"max_depth\"]\n",
    "min_samples_leaf = risultati.loc[0, \"min_samples_leaf\"]\n",
    "\n",
    "dtcTun = DecisionTreeClassifier(max_depth=max_depth, min_samples_leaf=min_samples_leaf, random_state=42)\n",
    "dtcTun.fit(X_train, y_train)\n",
    "\n",
    "y_pred = dtcTun.predict(X_val)\n",
    "acc_dtcTun = 100*accuracy_score(y_val, y_pred)\n",
    "print(\"profondità ottimale:\",max_depth)\n",
    "print(\"numero ottimale minimo di unità per foglia:\",min_samples_leaf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuratezza DecisionTreeClassifier(): {:.1f}%\".format(acc_dtcFull))\n",
    "print(\"Accuratezza DecisionTreeClassifier(max_depth={}, min_samples_leaf={}): {:.1f}%\".format(\n",
    "    max_depth, min_samples_leaf, acc_dtcTun))\n",
    "print(confusion_matrix(y_val, y_pred))\n",
    "\n",
    "MatriceConfusione(y_val, y_pred, nome_immagine=FIG_PATH + \"confusionMatrix-Tree.png\",\n",
    "                  title=\"Albero di classificazione ottimizzato\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importanze = dtcTun.feature_importances_\n",
    "variabili = espl.columns\n",
    "\n",
    "grafico_importanza_variabili(importanze, variabili)\n",
    "plt.savefig(FIG_PATH + \"importance-Tree.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Alberi di regressione penalizzati  <a id=tree-penalized> </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=20\n",
    "weights = y_train.value_counts()/y_train.value_counts().sum()\n",
    "weights[\"shake\"]/=i\n",
    "weights/=weights.sum()\n",
    "w = {ind:weights[ind] for ind in weights.index}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc = DecisionTreeClassifier(random_state=42,\n",
    "                             class_weight=w)\n",
    "\n",
    "dtc.fit(X_train, y_train)\n",
    "y_pred = dtc.predict(X_val)\n",
    "acc_dtc_pen = 100*accuracy_score(y_val, y_pred)\n",
    "print(\"Accuratezza DecisionTreeClassifier(): {:.1f}%\".format(acc_dtc_pen))\n",
    "MatriceConfusione(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END. Salvataggio dei risultati <a id=save> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tabella accuracy in file LaTeX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DataFrameToTable(df, file, cap=\"\", lab=\"\", digits=\"%.2f\"):\n",
    "    '''\n",
    "    Funzione che stampa un dataframe in tabella di LaTeX.\n",
    "    \n",
    "    Parametri\n",
    "    ---------\n",
    "    df : DataFrame\n",
    "        DataFrame da stampare in tabella\n",
    "        \n",
    "    file : string\n",
    "        Percorso completo al file in cui scrivere la tabella\n",
    "        \n",
    "    cap : string\n",
    "        Caption per la tabella\n",
    "    \n",
    "    lab : string\n",
    "        Label della tabella\n",
    "    \n",
    "    '''\n",
    "\n",
    "    tableEnvBegin = \"\\\\begin{table}[H]\\n\\\\centering\\n\"\n",
    "    tableEnvEnd = \"\\\\end{table}\"\n",
    "    c = 1 if cap else 0\n",
    "    l = 1 if lab else 0\n",
    "    caption=\"\\\\caption{\"*c + cap + \"}\\n\"*c\n",
    "    label=\"\\\\label{\"*l + lab + \"}\\n\"*l\n",
    "        \n",
    "    with open(file, mode=\"w\") as f:\n",
    "        f.write(tableEnvBegin + caption +\n",
    "                   df.to_latex(index=False, float_format=digits, column_format=\"c\"*len(df.columns)) +\n",
    "                   label + tableEnvEnd)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = pd.DataFrame([[\"Multinomiale\", acc_mn, 100*77/(7+1+77) ],\n",
    "             [\"LDA\", acc_lda, 100*53/(1+10+2+53)],\n",
    "             [\"QDA\", acc_qda, 100*77/(1+2+6+2+77)],\n",
    "             [\"Albero decisionale\", acc_dtcFull, 100*74/(1+10+4+73)],\n",
    "             [\"Albero decisionale ottimizzato\", acc_dtcTun, 100*71/(1+10+3+71)]], columns=[\"Modello\", \"Accuratezza %\", \"Shake corretti %\"])\n",
    "\n",
    "accuracy.sort_values(\"Accuratezza %\", inplace=True, ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataFrameToTable(accuracy, file = \"./relazione/tex/accuracy-table.tex\",\n",
    "                cap = \"Accuratezza per i modelli adattati sull'insieme di convalida.\",\n",
    "                lab = \"tab:acc\", )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = pd.DataFrame([[\"Multinomiale\", acc_mn_pen],\n",
    "                         [\"LDA\", acc_lda_pen],\n",
    "                         [\"QDA\", acc_qda_pen]],\n",
    "                        columns=[\"Modello\", \"Accuratezza %\"])\n",
    "accuracy.sort_values(\"Accuratezza %\", inplace=True, ascending=False)\n",
    "\n",
    "DataFrameToTable(accuracy, file = \"./relazione/tex/accuracy-table-pen.tex\",\n",
    "                 cap = \"Accuratezza per i modelli adattati sull'insieme di convalida.\",\n",
    "                 lab = \"tab:acc_pen\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Insieme di test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.read_pickle(\"X_test.pkl\")\n",
    "y_test = pd.read_pickle(\"y_test.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(penalty=\"l2\", C=float(\"inf\"), random_state=42, \n",
    "                               multi_class=\"multinomial\",solver=\"newton-cg\", max_iter=300)\n",
    "model.fit(pd.concat([X_train, X_val]), pd.concat([y_train, y_val]))\n",
    "y_pred = model.predict(X_test)\n",
    "acc_mn_test = 100*accuracy_score(y_test, y_pred)\n",
    "print(\"Accuratezza Multinomiale sull'insieme di test: {:.1f}%\".format(acc_mn_test))\n",
    "MatriceConfusione(y_test, y_pred,nome_immagine=FIG_PATH+\"confusionMatrix-Mn-test\"\n",
    "                 , title = \"Multinomiale\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = np.array(y_train.value_counts()/y_train.value_counts().sum())\n",
    "weights[-1] /= peso_shake_qda\n",
    "weights = weights/weights.sum()\n",
    "qda = QuadraticDiscriminantAnalysis(priors=weights)\n",
    "qda.fit(pd.concat([X_train, X_val]), pd.concat([y_train, y_val]))\n",
    "y_pred_qda = qda.predict(X_test)\n",
    "acc_qda_pen = 100*accuracy_score(y_test, y_pred_qda)\n",
    "print(\"Accuratezza QDA pesata sull'insieme di test: {:.1f}%\".format(acc_qda_pen))\n",
    "MatriceConfusione(y_test, y_pred_qda,nome_immagine=FIG_PATH+\"confusionMatrix-QDA-penalizzata-test\",\n",
    "                 title=\"QDA pesata\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grafici delle esplicative di esempio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_pickle(\"./X-2s.pkl\")\n",
    "X.drop(columns=\"user\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_shake = X[y == \"shake\"]\n",
    "X_scale = X[y == \"camminata\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.iloc[0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.arange(0, 150)\n",
    "for i in range(5):\n",
    "    plt.title(\"shake\", fontsize=13)\n",
    "    plt.ylabel(r\"$\\|a_j\\|\\;(\\mathrm{ m/s^2})$\", fontsize=13, rotation=0, labelpad=35)\n",
    "    plt.xlabel(\"indice\", fontsize=13, labelpad=15)\n",
    "    plt.plot(t, X_shake.iloc[i, :], color=\"darkblue\", alpha=0.55)\n",
    "    plt.savefig(FIG_PATH + \"shake.png\", dpi=300, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.arange(0, 150)\n",
    "for i in range(5):\n",
    "    plt.title(\"camminata\", fontsize=13)\n",
    "    plt.ylabel(r\"$\\|a_j\\|\\;(\\mathrm{ m/s^2})$\", fontsize=13, rotation=0, labelpad=35)\n",
    "    plt.xlabel(\"indice\", fontsize=13, labelpad=15)\n",
    "    plt.plot(t, X_scale.iloc[i, :], color=\"darkblue\", alpha=0.55)\n",
    "    plt.savefig(FIG_PATH + \"camminata.png\", dpi=300, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crop delle immagini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform\n",
    "if platform.system() == \"Linux\":\n",
    "    !mogrify -trim ./figure/*.png"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
