{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table Of Contents\n",
    " 1. [Caricamento dei dati](#load)<br>\n",
    "     1.1 [Grafici di esempio](#esempi)\n",
    " 2. [Calcolo delle variabili di riassunto](#variabili)\n",
    " 3. [Analisi esplorativa con `PCA`, `ICA`, `t-SNE`](#esplorativa)\n",
    " 4. [Modello multinomiale](#multinomiale)<br>\n",
    "     4.1 [Modello multinomiale penalizzato](#multinomiale-pen)\n",
    " 5. [Analisi discriminante](#lda-qda)<br>\n",
    "     5.1 [Analisi discriminante penalizzata](#da-pen)\n",
    " 6. [Alberi di regressione](#tree)<br>\n",
    "     6.1 [Alberi di regressione penalizzati](#tree-penalized)<br>\n",
    "\n",
    "END. [Salvataggio dei dati](#save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funzioni base:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import seaborn as sns\n",
    "import tqdm\n",
    "\n",
    "# Font di LaTeX\n",
    "# from matplotlib import rc\n",
    "\n",
    "# Scikit-Learn\n",
    "from sklearn.model_selection import train_test_split, ParameterGrid\n",
    "from sklearn.decomposition import PCA, FastICA\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis, LinearDiscriminantAnalysis\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "import graphviz\n",
    "# Funzioni custom\n",
    "from funzioni import AbsMeanVarDeriv, Whiten,ScatterGroup, MatriceConfusione, indice_gini\n",
    "from funzioni import tasso_errata_classificazione, grafico_metrica_iperparametro, grafico_metrica_iperparametri\n",
    "from funzioni.grafici import grafico_importanza_variabili"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Caricamento dei dati <a id=load> </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_DATA = './PhonePi/data/'\n",
    "FIG_PATH = './figure/'\n",
    "DIR = [os.path.join(PATH_DATA, o) for o in os.listdir(PATH_DATA) \n",
    "                    if os.path.isdir(os.path.join(PATH_DATA,o))]\n",
    "tipo=[(dir.split(\"/\")[-1]).split(\".\")[0] for dir in DIR]\n",
    "tipo=[dir.split(\"-\")[0] for dir in tipo]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 150 # numero osservazioni per intervallo\n",
    "nomi_colonna=[\"user\",\"azione\"]\n",
    "nomi_colonna.extend([\"a\"+str(i) for i in range(p)])\n",
    "nomi_colonna\n",
    "X=pd.DataFrame(columns=nomi_colonna)\n",
    "\n",
    "for i in tqdm.tqdm(range(len(DIR))):\n",
    "    data = pd.read_csv(DIR[i] + \"/accelerometer.txt\", names = [\"user\", \"type\", \"t\", \"ax\", \"ay\", \"az\"]) # lettura dati\n",
    "    data[\"t\"] = data[\"t\"] - data[\"t\"].iloc[0] # t0 = 0\n",
    "    data = data[(data[\"t\"] > 7000) & (data[\"t\"] < (data[\"t\"].max()-7000))] # tolti i primi e ultimi 7 secondi\n",
    "    data.reset_index(drop=True, inplace=True) # ripristinati gli indici da 0 in avanti\n",
    "    data[\"a\"] = (pd.to_numeric(data[\"ax\"])**2 + pd.to_numeric(data[\"ay\"])**2 + pd.to_numeric(data[\"az\"])**2)**0.5 # accelerazione in modulo\n",
    "    nome = [data.user[j] for j in range(0,len(data)-p, p)] # intervalli di dt*100ms\n",
    "    tipologia=[tipo[i]]*len(nome)\n",
    "    righe=[[nome[j],tipologia[j]] for j in range(len(nome))]\n",
    "    [righe[j].extend(list(data.a[j*p:(j+1)*p])) for j in range(len(nome))]\n",
    "    X=pd.concat([X,pd.DataFrame(righe,columns=nomi_colonna)],ignore_index=True) # ignore_index=T per avere indici consecutivi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Grafici di esempio <a id=esempi> </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIRM = ['./PhonePi/data/scale-martina',\n",
    "        './PhonePi/data/salti-daniele',\n",
    "        './PhonePi/data/shake-anna',\n",
    "        './PhonePi/data/corsa_tasca-alberto'\n",
    "       ]\n",
    "loc = [1,2,3,4]\n",
    "plt.figure(figsize=(7.5*len(DIRM),5.5*len(DIRM)))\n",
    "for i in range(4):\n",
    "    data = pd.read_csv(DIRM[i] + \"/accelerometer.txt\", names = [\"user\", \"type\", \"t\", \"ax\", \"ay\", \"az\"])\n",
    "    data[\"t\"] = data[\"t\"] - data[\"t\"].iloc[0]\n",
    "    data = data[(data[\"t\"] > 7000) & (data[\"t\"] < (data[\"t\"].max()-7000))]\n",
    "    data[\"a\"] = (pd.to_numeric(data[\"ax\"])**2 + pd.to_numeric(data[\"ay\"])**2 + pd.to_numeric(data[\"az\"])**2)**0.5 # accelerazione in modulo\n",
    "    ax = plt.subplot(2, 2, i+1 , ylim=(0,120), xlim = (10000,30000))\n",
    "    ax.set_ylabel(r\"$\\|\\|a\\|\\|\\;(\\mathrm{ m/s}^2)$\", rotation=0)\n",
    "    ax.yaxis.set_label_coords(-0.1,0.7)\n",
    "    ax.set_xlabel(r\"$t \\;(\\mathrm{ ms})$\")\n",
    "    ax.set_title((DIRM[i].split(\"/\")[-1]).split(\"-\")[0])\n",
    "    plt.plot(data[\"t\"],data[\"a\"])\n",
    "    plt.savefig(FIG_PATH+\"espl.png\", dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Calcolo delle variabili di riassunto <a id=variabili> </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = X.azione\n",
    "X.drop(\"azione\", axis=1, inplace=True)\n",
    "Xnum = X.drop(\"user\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxA = Xnum.max(1) # massimo accelerazione\n",
    "MVDeriv = AbsMeanVarDeriv(Xnum, 10) # variazione media della derivata\n",
    "meanA = Xnum.mean(axis=1)\n",
    "varA = Xnum.var(axis=1)\n",
    "medA = Xnum.median(axis=1)\n",
    "minA = Xnum.min(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "espl = pd.concat([maxA, MVDeriv, meanA, varA, medA, minA], axis=1)\n",
    "espl.columns=[\"maxA\", \"MVDeriv\", \"meanA\", \"varA\", \"medA\", \"minA\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.to_pickle(\"X-2s.pkl\")\n",
    "y.to_pickle(\"y-2s.pkl\")\n",
    "espl.to_pickle(\"espl.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#per luisa\n",
    "X.to_csv(\"X-2s.csv\")\n",
    "y.to_csv(\"y-2s.csv\")\n",
    "espl.to_csv(\"espl.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(espl, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Analisi esplorativa con `PCA`, `ICA`, `t-SNE` <a id=esplorativa> </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sbiancamento dei dati\n",
    "esplWh = Whiten().fit_transform(espl)\n",
    "\n",
    "pca = PCA(n_components=2, random_state=42)\n",
    "esplPCA = pca.fit_transform(esplWh)\n",
    "\n",
    "ica = FastICA(n_components=2, random_state=42)\n",
    "esplICA = ica.fit_transform(esplWh)\n",
    "\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "esplTSNE = tsne.fit_transform(esplWh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for title,dat in zip([\"PCA\",\"ICA\",\"t-SNE\"], [esplPCA, esplICA, esplTSNE]):\n",
    "    fig, ax = ScatterGroup(pd.DataFrame(dat, columns=[\"Prima componente\", \"Seconda componente\"]),\n",
    "                       grp=y, palette=\"colorblind\")\n",
    "    fig.set_figwidth(11)\n",
    "    fig.set_figheight(6)\n",
    "    ax.set_title(title)\n",
    "    plt.legend(bbox_to_anchor=(1,0.7))\n",
    "    plt.savefig(FIG_PATH+title+\".png\", bbox_inches=\"tight\", dpi=180)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Modello multinomiale <a id=multinomiale> </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glmMult = LogisticRegression(penalty=\"l2\", C=float(\"inf\"), random_state=42, multi_class=\"multinomial\",\n",
    "                             solver=\"newton-cg\", max_iter=300)\n",
    "fit = glmMult.fit(X_train, y_train)\n",
    "y_pred = fit.predict(X_val)\n",
    "\n",
    "acc_mn = 100*accuracy_score(y_val, y_pred)\n",
    "print(\"Regressione multinomiale: {:.1f}% di accuratezza\".format(acc_mn))\n",
    "MatriceConfusione(y_val, y_pred)\n",
    "plt.savefig(FIG_PATH+\"confusionMatrix-Mn.png\", dpi=300, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Modello multinomiale penalizzato <a id=multinomiale-pen></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab = y.unique()\n",
    "lab.sort()\n",
    "print(lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PesiShakeMn(val):\n",
    "    '''\n",
    "    Funzione per modificare i pesi nel modello multinomiale\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    Modello : Funzione di classificazione (LDA o QDA)\n",
    "    \n",
    "    val : array di valori per cui dividere il peso base della classe shake\n",
    "    '''\n",
    "\n",
    "    lista_acc=[]\n",
    "    lista_veri_positivi=[]\n",
    "    for i in tqdm.tqdm(val):\n",
    "        weights = y_train.value_counts()/y_train.value_counts().sum()\n",
    "        weights[\"shake\"]/=i\n",
    "        weights/=weights.sum()\n",
    "        w = {ind:weights[ind] for ind in weights.index}\n",
    "        model = LogisticRegression(penalty=\"l2\", C=float(\"inf\"), random_state=42, \n",
    "                               multi_class=\"multinomial\",solver=\"newton-cg\", max_iter=100, class_weight=w)\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_val)\n",
    "        lista_acc.append(100*accuracy_score(y_val, y_pred))\n",
    "        lista_veri_positivi.append(100*(confusion_matrix(y_val, y_pred, labels=lab)[-1,-1]/confusion_matrix(y_val, y_pred,labels=lab)[:,-1].sum()))\n",
    "        \n",
    "    return lista_acc, lista_veri_positivi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pesi = np.arange(1, 13, 0.5)\n",
    "lista_acc_mn, lista_veri_positivi_mn = PesiShakeMn(val=pesi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(lista_acc_mn, label = \"accuratezza\")\n",
    "plt.plot(lista_veri_positivi_mn, label = \"veri positivi\")\n",
    "plt.title(\"Multinomiale\")\n",
    "plt.xlabel(\"iterazione\")\n",
    "plt.ylabel(\"%\")\n",
    "plt.legend(bbox_to_anchor=(1.31,0.7))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------- TODO ---------------------#\n",
    "# Prendere il peso migliore per la multinomiale #\n",
    "#-----------------------------------------------#\n",
    "#w = ...\n",
    "\n",
    "\n",
    "#glmMult = LogisticRegression(penalty=\"l2\", C=float(\"inf\"), random_state=42, multi_class=\"multinomial\",\n",
    "#                              solver=\"newton-cg\", max_iter=300, class_weight=w)\n",
    "#fit = glmMult.fit(X_train, y_train)\n",
    "# y_pred = fit.predict(X_val)\n",
    "\n",
    "# acc_mn_pen = 100*accuracy_score(y_val, y_pred)\n",
    "# print(\"Regressione multinomiale penalizzata: {:.1f}% di accuratezza\".format(acc_mn_pen))\n",
    "# MatriceConfusione(y_val, y_pred)\n",
    "# plt.savefig(FIG_PATH+\"confusionMatrix-Mn-penalizzata.png\", dpi=300, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Analisi discriminante lineare e quadratica <a id=lda-qda> </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LinearDiscriminantAnalysis()\n",
    "X_lda=lda.fit(X_train, y_train)\n",
    "y_pred_lda = lda.predict(X_val)\n",
    "acc_lda = 100*accuracy_score(y_val, y_pred_lda)\n",
    "print(\"Accuratezza LDA: {:.1f}%\".format(acc_lda))\n",
    "MatriceConfusione(y_val, y_pred_lda,nome_immagine=FIG_PATH+\"confusionMatrix-LDA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qda = QuadraticDiscriminantAnalysis()\n",
    "qda.fit(X_train, y_train)\n",
    "y_pred_qda = qda.predict(X_val)\n",
    "acc_qda = 100*accuracy_score(y_val, y_pred_qda)\n",
    "print(\"Accuratezza QDA: {:.1f}%\".format(acc_qda))\n",
    "MatriceConfusione(y_val, y_pred_qda,nome_immagine=FIG_PATH+\"confusionMatrix-QDA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Analisi discriminante penalizzata <a id=da-pen> </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lda.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PesiShakeDA(Modello, val):\n",
    "    '''\n",
    "    Funzione per modificare i pesi delle analisi discriminanti lineare e quadratica.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    Modello : Funzione di classificazione (LDA o QDA)\n",
    "    \n",
    "    val : array di valori per cui dividere il peso base della classe shake\n",
    "    '''\n",
    "\n",
    "    lista_acc=[]\n",
    "    lista_veri_positivi=[]\n",
    "    w=[]\n",
    "    for i in val:\n",
    "        weights = np.array(y_train.value_counts()/y_train.value_counts().sum())\n",
    "        weights[-1] /= i\n",
    "        weights = weights/weights.sum()\n",
    "        w.append(weights[-1])\n",
    "        model = Modello(priors=weights)\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_val)\n",
    "        lista_acc.append(100*accuracy_score(y_val, y_pred))\n",
    "        lista_veri_positivi.append(100*(confusion_matrix(y_val, y_pred, labels=lab)[-1,-1]/confusion_matrix(y_val, y_pred,labels=lab)[:,-1].sum()))\n",
    "        \n",
    "    return w, lista_acc, lista_veri_positivi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA e QDA penalizzate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in pratica per pesi crescenti assegnati alla classe dello shake si nota che la percentuale di veri positivi aumenta\n",
    "# e l'accuratezza ovviamente diminuisce. Se vogliamo che l'errore di classificare shake qualcosa che non è shake sia nullo\n",
    "# (o <0.01) scegliamo il primo peso che mi porta ad avere veri_positivi uguale a 100 (o 99) in modo da scegliere \n",
    "# il modello con l'accuratezza migliore fra quelli che non sbagliano lo shake\n",
    "\n",
    "val = np.arange(1.1, 12, 0.1) # lista di divisori del peso per la classe\n",
    "\n",
    "pesi_lda, lista_acc_lda, lista_veri_positivi_lda = PesiShakeDA(LinearDiscriminantAnalysis, val)\n",
    "plt.plot(lista_acc_lda, label = \"accuratezza\")\n",
    "plt.plot(lista_veri_positivi_lda, label = \"veri positivi\")\n",
    "plt.title(\"LDA\")\n",
    "plt.xlabel(\"iterazione\")\n",
    "plt.ylabel(\"%\")\n",
    "plt.legend(bbox_to_anchor=(1.31,0.7))\n",
    "plt.show()\n",
    "\n",
    "pesi_qda, lista_acc_qda, lista_veri_positivi_qda = PesiShakeDA(QuadraticDiscriminantAnalysis, val)\n",
    "plt.plot(lista_acc_qda, label = \"accuratezza\")\n",
    "plt.plot(lista_veri_positivi_qda, label = \"veri positivi\")\n",
    "plt.title(\"QDA\")\n",
    "plt.xlabel(\"iterazione\")\n",
    "plt.ylabel(\"%\")\n",
    "plt.legend(bbox_to_anchor=(1.31,0.7))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_veri_positivi_qda[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_veri_positivi_lda=np.array(lista_veri_positivi_lda)\n",
    "num_iterazione_lda=np.min(np.where(lista_veri_positivi_lda>99))\n",
    "peso_shake_lda=np.arange(1.1,12,0.1)[num_iterazione_lda]\n",
    "peso_shake_lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_veri_positivi_qda=np.array(lista_veri_positivi_qda)\n",
    "num_iterazione_qda=np.min(np.where(lista_veri_positivi_qda>98))\n",
    "peso_shake_qda=np.arange(1.1,12,0.1)[num_iterazione_qda]\n",
    "peso_shake_qda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = np.array(y_train.value_counts()/y_train.value_counts().sum())\n",
    "weights[-1] /= peso_shake_lda\n",
    "weights = weights/weights.sum()\n",
    "lda = LinearDiscriminantAnalysis(priors=weights)\n",
    "X_lda=lda.fit(X_train, y_train)\n",
    "y_pred_lda = lda.predict(X_val)\n",
    "acc_lda = 100*accuracy_score(y_val, y_pred_lda)\n",
    "print(\"Accuratezza LDA: {:.1f}%\".format(acc_lda))\n",
    "MatriceConfusione(y_val, y_pred_lda,nome_immagine=FIG_PATH+\"confusionMatrix-LDA-penalizzata\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = np.array(y_train.value_counts()/y_train.value_counts().sum())\n",
    "weights[-1] /= peso_shake_qda\n",
    "weights = weights/weights.sum()\n",
    "qda = QuadraticDiscriminantAnalysis(priors=weights)\n",
    "qda.fit(X_train, y_train)\n",
    "y_pred_qda = qda.predict(X_val)\n",
    "acc_qda = 100*accuracy_score(y_val, y_pred_qda)\n",
    "print(\"Accuratezza QDA: {:.1f}%\".format(acc_qda))\n",
    "MatriceConfusione(y_val, y_pred_qda,nome_immagine=FIG_PATH+\"confusionMatrix-QDA-penalizzata\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Alberi di regressione <a id=tree> </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Albero stimato sul training, senza vincoli (albero completo)\n",
    "dtc = DecisionTreeClassifier(random_state=42)\n",
    "dtc.fit(X_train, y_train)\n",
    "y_pred = dtc.predict(X_val)\n",
    "acc_dtcFull = 100*accuracy_score(y_val, y_pred)\n",
    "\n",
    "print(\"Accuratezza DecisionTreeClassifier(): {:.2f}%\".format(acc_dtcFull))\n",
    "MatriceConfusione(y_val, y_pred)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxDepth = dtc.tree_.max_depth\n",
    "minObs = len(X_train) // 2\n",
    "print(\"Profondità dell'albero allenato senza restrizioni: {}\".format(maxDepth))\n",
    "print(\"Massimo numero minimo di osservazioni in una foglia: {}\".format(minObs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = ParameterGrid({\n",
    "    'max_depth': np.arange(1, dtc.tree_.max_depth+1),\n",
    "    'min_samples_leaf': 2 ** np.arange(int(np.log2(minObs) + 1)),\n",
    "})\n",
    "print(param_grid.param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "risultati = []\n",
    "\n",
    "for params in tqdm.tqdm(param_grid):\n",
    "    dtc = DecisionTreeClassifier(random_state=42, **params)\n",
    "    dtc.fit(X_train, y_train)\n",
    "    y_pred = dtc.predict(X_val)\n",
    "    params[\"accuracy_score\"] = accuracy_score(y_val, y_pred)\n",
    "    risultati.append(params)\n",
    "\n",
    "risultati = pd.DataFrame(risultati).sort_values([\"accuracy_score\", \"max_depth\"], ascending=[False, True])\n",
    "risultati.reset_index(drop=True, inplace=True)\n",
    "print(\"Primi 5:\")\n",
    "display(risultati.head())\n",
    "\n",
    "print(\"Ultimi 5:\")\n",
    "risultati.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(121)\n",
    "grafico_metrica_iperparametro(risultati, \"max_depth\", \"accuracy_score\", alpha=0.5)\n",
    "\n",
    "plt.subplot(122)\n",
    "grafico_metrica_iperparametro(risultati, \"min_samples_leaf\", \"accuracy_score\", alpha=0.5)\n",
    "plt.xscale(\"log\", basex=2)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "grafico_metrica_iperparametri(risultati, \"max_depth\", \"min_samples_leaf\", \"accuracy_score\")\n",
    "plt.yscale(\"log\", basey=2)\n",
    "plt.savefig(FIG_PATH + \"iperparametri-Tree.png\", dpi=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth = risultati.loc[0, \"max_depth\"]\n",
    "min_samples_leaf = risultati.loc[0, \"min_samples_leaf\"]\n",
    "\n",
    "dtcTun = DecisionTreeClassifier(max_depth=max_depth, min_samples_leaf=min_samples_leaf, random_state=42)\n",
    "dtcTun.fit(X_train, y_train)\n",
    "\n",
    "y_pred = dtcTun.predict(X_val)\n",
    "acc_dtcTun = 100*accuracy_score(y_val, y_pred)\n",
    "print(\"profondità ottimale:\",max_depth)\n",
    "print(\"numero ottimale minimo di unità per foglia:\",min_samples_leaf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuratezza DecisionTreeClassifier(): {:.1f}%\".format(acc_dtcFull))\n",
    "print(\"Accuratezza DecisionTreeClassifier(max_depth={}, min_samples_leaf={}): {:.1f}%\".format(\n",
    "    max_depth, min_samples_leaf, acc_dtcTun))\n",
    "print(confusion_matrix(y_val, y_pred))\n",
    "\n",
    "MatriceConfusione(y_val, y_pred)\n",
    "plt.savefig(FIG_PATH + \"confusionMatrix-Tree.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importanze = dtcTun.feature_importances_\n",
    "variabili = espl.columns\n",
    "\n",
    "grafico_importanza_variabili(importanze, variabili)\n",
    "plt.savefig(FIG_PATH + \"importance-Tree.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 Alberi di regressione penalizzati  <a id=tree-penalized> </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END. Salvataggio dei risultati <a id=save> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tabella accuracy in file LaTeX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tableEnvBegin = \"\\\\begin{table}[H]\\n\\\\centering\"\n",
    "tableEnvEnd = \"\\end{table}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = pd.DataFrame([[\"Multinomiale\", acc_mn],\n",
    "             [\"LDA\", acc_lda],\n",
    "             [\"QDA\", acc_qda],\n",
    "             [\"Decision Tree\", acc_dtcFull],\n",
    "             [\"Optimized Decision Tree\", acc_dtcTun]], columns=[\"Modello\", \"Accuratezza %\"])\n",
    "\n",
    "accuracy.sort_values(\"Accuratezza %\", inplace=True)\n",
    "caption='\\\\caption{Accuratezza per i modelli adattati.}\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./relazione/tex/accuracy-table.tex\", mode=\"w\") as file:\n",
    "    file.write(tableEnvBegin + caption + accuracy.to_latex(index=False, float_format=\"%.2f\", column_format=\"cc\") + tableEnvEnd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: tabella accuracy - falsi positivi shake"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crop delle immagini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform\n",
    "if platform.system() == \"Linux\":\n",
    "    !mogrify -trim ./figure/*.png"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
